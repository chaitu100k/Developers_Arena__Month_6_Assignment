{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cbca0e0b",
   "metadata": {},
   "source": [
    "# LSTM-Ready Feature Engineering\n",
    "\n",
    "Single-cell notebook. Edit `DATA_PATH` at the top to point to your CSV file (e.g., `data/working_copy.csv`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8152d59d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data from: C:/Users/Asus/Documents/Developers_Arena_Internship_Files/Month_6_Internship_files/traffic_flow_project/traffic_flow_project/data/synthetic_traffic_dataset.csv\n",
      "Loaded: (6048, 5)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>timestamp</th>\n",
       "      <th>sensor_id</th>\n",
       "      <th>vehicle_count</th>\n",
       "      <th>avg_speed</th>\n",
       "      <th>occupancy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2023-01-01 00:00:00</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>62.91</td>\n",
       "      <td>0.02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2023-01-01 00:05:00</td>\n",
       "      <td>1</td>\n",
       "      <td>13</td>\n",
       "      <td>62.51</td>\n",
       "      <td>0.13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2023-01-01 00:10:00</td>\n",
       "      <td>1</td>\n",
       "      <td>11</td>\n",
       "      <td>59.90</td>\n",
       "      <td>0.11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2023-01-01 00:15:00</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>60.32</td>\n",
       "      <td>0.09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2023-01-01 00:20:00</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>60.81</td>\n",
       "      <td>0.06</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            timestamp  sensor_id  vehicle_count  avg_speed  occupancy\n",
       "0 2023-01-01 00:00:00          1              2      62.91       0.02\n",
       "1 2023-01-01 00:05:00          1             13      62.51       0.13\n",
       "2 2023-01-01 00:10:00          1             11      59.90       0.11\n",
       "3 2023-01-01 00:15:00          1              9      60.32       0.09\n",
       "4 2023-01-01 00:20:00          1              6      60.81       0.06"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After resampling: (6048, 5)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Asus\\AppData\\Local\\Temp\\ipykernel_3024\\3290464597.py:52: FutureWarning: 'T' is deprecated and will be removed in a future version, please use 'min' instead.\n",
      "  res = sensor_df[numeric_cols].resample(rule).mean()\n",
      "C:\\Users\\Asus\\AppData\\Local\\Temp\\ipykernel_3024\\3290464597.py:52: FutureWarning: 'T' is deprecated and will be removed in a future version, please use 'min' instead.\n",
      "  res = sensor_df[numeric_cols].resample(rule).mean()\n",
      "C:\\Users\\Asus\\AppData\\Local\\Temp\\ipykernel_3024\\3290464597.py:52: FutureWarning: 'T' is deprecated and will be removed in a future version, please use 'min' instead.\n",
      "  res = sensor_df[numeric_cols].resample(rule).mean()\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>timestamp</th>\n",
       "      <th>sensor_id</th>\n",
       "      <th>vehicle_count</th>\n",
       "      <th>avg_speed</th>\n",
       "      <th>occupancy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2023-01-01 00:00:00</td>\n",
       "      <td>1</td>\n",
       "      <td>2.0</td>\n",
       "      <td>62.91</td>\n",
       "      <td>0.02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2023-01-01 00:05:00</td>\n",
       "      <td>1</td>\n",
       "      <td>13.0</td>\n",
       "      <td>62.51</td>\n",
       "      <td>0.13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2023-01-01 00:10:00</td>\n",
       "      <td>1</td>\n",
       "      <td>11.0</td>\n",
       "      <td>59.90</td>\n",
       "      <td>0.11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2023-01-01 00:15:00</td>\n",
       "      <td>1</td>\n",
       "      <td>9.0</td>\n",
       "      <td>60.32</td>\n",
       "      <td>0.09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2023-01-01 00:20:00</td>\n",
       "      <td>1</td>\n",
       "      <td>6.0</td>\n",
       "      <td>60.81</td>\n",
       "      <td>0.06</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            timestamp  sensor_id  vehicle_count  avg_speed  occupancy\n",
       "0 2023-01-01 00:00:00          1            2.0      62.91       0.02\n",
       "1 2023-01-01 00:05:00          1           13.0      62.51       0.13\n",
       "2 2023-01-01 00:10:00          1           11.0      59.90       0.11\n",
       "3 2023-01-01 00:15:00          1            9.0      60.32       0.09\n",
       "4 2023-01-01 00:20:00          1            6.0      60.81       0.06"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>timestamp</th>\n",
       "      <th>sensor_id</th>\n",
       "      <th>vehicle_count</th>\n",
       "      <th>avg_speed</th>\n",
       "      <th>occupancy</th>\n",
       "      <th>hour</th>\n",
       "      <th>minute</th>\n",
       "      <th>dayofweek</th>\n",
       "      <th>hour_sin</th>\n",
       "      <th>hour_cos</th>\n",
       "      <th>dow_sin</th>\n",
       "      <th>dow_cos</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2023-01-01 00:00:00</td>\n",
       "      <td>1</td>\n",
       "      <td>2.0</td>\n",
       "      <td>62.91</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.781831</td>\n",
       "      <td>0.62349</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2023-01-01 00:05:00</td>\n",
       "      <td>1</td>\n",
       "      <td>13.0</td>\n",
       "      <td>62.51</td>\n",
       "      <td>0.13</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.781831</td>\n",
       "      <td>0.62349</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2023-01-01 00:10:00</td>\n",
       "      <td>1</td>\n",
       "      <td>11.0</td>\n",
       "      <td>59.90</td>\n",
       "      <td>0.11</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>6</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.781831</td>\n",
       "      <td>0.62349</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2023-01-01 00:15:00</td>\n",
       "      <td>1</td>\n",
       "      <td>9.0</td>\n",
       "      <td>60.32</td>\n",
       "      <td>0.09</td>\n",
       "      <td>0</td>\n",
       "      <td>15</td>\n",
       "      <td>6</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.781831</td>\n",
       "      <td>0.62349</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2023-01-01 00:20:00</td>\n",
       "      <td>1</td>\n",
       "      <td>6.0</td>\n",
       "      <td>60.81</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0</td>\n",
       "      <td>20</td>\n",
       "      <td>6</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.781831</td>\n",
       "      <td>0.62349</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            timestamp  sensor_id  vehicle_count  avg_speed  occupancy  hour  \\\n",
       "0 2023-01-01 00:00:00          1            2.0      62.91       0.02     0   \n",
       "1 2023-01-01 00:05:00          1           13.0      62.51       0.13     0   \n",
       "2 2023-01-01 00:10:00          1           11.0      59.90       0.11     0   \n",
       "3 2023-01-01 00:15:00          1            9.0      60.32       0.09     0   \n",
       "4 2023-01-01 00:20:00          1            6.0      60.81       0.06     0   \n",
       "\n",
       "   minute  dayofweek  hour_sin  hour_cos   dow_sin  dow_cos  \n",
       "0       0          6       0.0       1.0 -0.781831  0.62349  \n",
       "1       5          6       0.0       1.0 -0.781831  0.62349  \n",
       "2      10          6       0.0       1.0 -0.781831  0.62349  \n",
       "3      15          6       0.0       1.0 -0.781831  0.62349  \n",
       "4      20          6       0.0       1.0 -0.781831  0.62349  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dropped 36 rows due to lag/rolling NaNs. Remaining: 6012\n",
      "Using feature cols: ['hour_sin', 'hour_cos', 'dow_sin', 'dow_cos', 'avg_speed', 'occupancy', 'avg_speed_lag1', 'avg_speed_lag2', 'avg_speed_lag3', 'occupancy_lag1', 'occupancy_lag2', 'occupancy_lag3', 'vehicle_count_lag1', 'vehicle_count_lag2', 'vehicle_count_lag3', 'vehicle_count_rmean_3', 'vehicle_count_rstd_3']\n",
      "After final drop: (6012, 46)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>timestamp</th>\n",
       "      <th>sensor_id</th>\n",
       "      <th>vehicle_count</th>\n",
       "      <th>avg_speed</th>\n",
       "      <th>occupancy</th>\n",
       "      <th>hour</th>\n",
       "      <th>minute</th>\n",
       "      <th>dayofweek</th>\n",
       "      <th>hour_sin</th>\n",
       "      <th>hour_cos</th>\n",
       "      <th>...</th>\n",
       "      <th>occupancy_rstd_6</th>\n",
       "      <th>vehicle_count_rmean_6</th>\n",
       "      <th>vehicle_count_rstd_6</th>\n",
       "      <th>avg_speed_rmean_12</th>\n",
       "      <th>avg_speed_rstd_12</th>\n",
       "      <th>occupancy_rmean_12</th>\n",
       "      <th>occupancy_rstd_12</th>\n",
       "      <th>vehicle_count_rmean_12</th>\n",
       "      <th>vehicle_count_rstd_12</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2023-01-01 01:00:00</td>\n",
       "      <td>1</td>\n",
       "      <td>14.0</td>\n",
       "      <td>65.24</td>\n",
       "      <td>0.14</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0.258819</td>\n",
       "      <td>0.965926</td>\n",
       "      <td>...</td>\n",
       "      <td>0.022286</td>\n",
       "      <td>9.166667</td>\n",
       "      <td>2.228602</td>\n",
       "      <td>61.990000</td>\n",
       "      <td>1.704145</td>\n",
       "      <td>0.087500</td>\n",
       "      <td>0.030488</td>\n",
       "      <td>8.750000</td>\n",
       "      <td>3.048845</td>\n",
       "      <td>14.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2023-01-01 01:05:00</td>\n",
       "      <td>1</td>\n",
       "      <td>9.0</td>\n",
       "      <td>60.85</td>\n",
       "      <td>0.09</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>0.258819</td>\n",
       "      <td>0.965926</td>\n",
       "      <td>...</td>\n",
       "      <td>0.028577</td>\n",
       "      <td>10.166667</td>\n",
       "      <td>2.857738</td>\n",
       "      <td>62.184167</td>\n",
       "      <td>1.935527</td>\n",
       "      <td>0.097500</td>\n",
       "      <td>0.025628</td>\n",
       "      <td>9.750000</td>\n",
       "      <td>2.562846</td>\n",
       "      <td>9.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2023-01-01 01:10:00</td>\n",
       "      <td>1</td>\n",
       "      <td>14.0</td>\n",
       "      <td>65.18</td>\n",
       "      <td>0.14</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>6</td>\n",
       "      <td>0.258819</td>\n",
       "      <td>0.965926</td>\n",
       "      <td>...</td>\n",
       "      <td>0.027325</td>\n",
       "      <td>10.333333</td>\n",
       "      <td>2.732520</td>\n",
       "      <td>62.045833</td>\n",
       "      <td>1.969151</td>\n",
       "      <td>0.094167</td>\n",
       "      <td>0.023533</td>\n",
       "      <td>9.416667</td>\n",
       "      <td>2.353270</td>\n",
       "      <td>14.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2023-01-01 01:15:00</td>\n",
       "      <td>1</td>\n",
       "      <td>7.0</td>\n",
       "      <td>62.22</td>\n",
       "      <td>0.07</td>\n",
       "      <td>1</td>\n",
       "      <td>15</td>\n",
       "      <td>6</td>\n",
       "      <td>0.258819</td>\n",
       "      <td>0.965926</td>\n",
       "      <td>...</td>\n",
       "      <td>0.028048</td>\n",
       "      <td>11.333333</td>\n",
       "      <td>2.804758</td>\n",
       "      <td>62.485833</td>\n",
       "      <td>2.034884</td>\n",
       "      <td>0.096667</td>\n",
       "      <td>0.026742</td>\n",
       "      <td>9.666667</td>\n",
       "      <td>2.674232</td>\n",
       "      <td>7.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2023-01-01 01:20:00</td>\n",
       "      <td>1</td>\n",
       "      <td>5.0</td>\n",
       "      <td>61.25</td>\n",
       "      <td>0.05</td>\n",
       "      <td>1</td>\n",
       "      <td>20</td>\n",
       "      <td>6</td>\n",
       "      <td>0.258819</td>\n",
       "      <td>0.965926</td>\n",
       "      <td>...</td>\n",
       "      <td>0.028048</td>\n",
       "      <td>11.333333</td>\n",
       "      <td>2.804758</td>\n",
       "      <td>62.644167</td>\n",
       "      <td>1.921819</td>\n",
       "      <td>0.095000</td>\n",
       "      <td>0.027798</td>\n",
       "      <td>9.500000</td>\n",
       "      <td>2.779797</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 46 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            timestamp  sensor_id  vehicle_count  avg_speed  occupancy  hour  \\\n",
       "0 2023-01-01 01:00:00          1           14.0      65.24       0.14     1   \n",
       "1 2023-01-01 01:05:00          1            9.0      60.85       0.09     1   \n",
       "2 2023-01-01 01:10:00          1           14.0      65.18       0.14     1   \n",
       "3 2023-01-01 01:15:00          1            7.0      62.22       0.07     1   \n",
       "4 2023-01-01 01:20:00          1            5.0      61.25       0.05     1   \n",
       "\n",
       "   minute  dayofweek  hour_sin  hour_cos  ...  occupancy_rstd_6  \\\n",
       "0       0          6  0.258819  0.965926  ...          0.022286   \n",
       "1       5          6  0.258819  0.965926  ...          0.028577   \n",
       "2      10          6  0.258819  0.965926  ...          0.027325   \n",
       "3      15          6  0.258819  0.965926  ...          0.028048   \n",
       "4      20          6  0.258819  0.965926  ...          0.028048   \n",
       "\n",
       "   vehicle_count_rmean_6  vehicle_count_rstd_6  avg_speed_rmean_12  \\\n",
       "0               9.166667              2.228602           61.990000   \n",
       "1              10.166667              2.857738           62.184167   \n",
       "2              10.333333              2.732520           62.045833   \n",
       "3              11.333333              2.804758           62.485833   \n",
       "4              11.333333              2.804758           62.644167   \n",
       "\n",
       "   avg_speed_rstd_12  occupancy_rmean_12  occupancy_rstd_12  \\\n",
       "0           1.704145            0.087500           0.030488   \n",
       "1           1.935527            0.097500           0.025628   \n",
       "2           1.969151            0.094167           0.023533   \n",
       "3           2.034884            0.096667           0.026742   \n",
       "4           1.921819            0.095000           0.027798   \n",
       "\n",
       "   vehicle_count_rmean_12  vehicle_count_rstd_12  target  \n",
       "0                8.750000               3.048845    14.0  \n",
       "1                9.750000               2.562846     9.0  \n",
       "2                9.416667               2.353270    14.0  \n",
       "3                9.666667               2.674232     7.0  \n",
       "4                9.500000               2.779797     5.0  \n",
       "\n",
       "[5 rows x 46 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train/Val/Test shapes: (0, 46) (0, 46) (6012, 46)\n",
      "TOTAL rows: 6012\n",
      "Timestamp range: 2023-01-01 01:00:00 to 2023-01-07 23:55:00\n",
      "Unique sensors: 3\n",
      "Rows per sensor:\n",
      " sensor_id\n",
      "1    2004\n",
      "2    2004\n",
      "3    2004\n",
      "Name: count, dtype: int64\n",
      "After day-split -> Train/Val/Test sizes: 0 0 6012\n",
      "Day-split produced empty/too-small train set. Falling back to time-quantile split.\n",
      "After quantile-split -> Train/Val/Test sizes: 4209 903 900\n",
      "Using feature columns for scaler: ['hour_sin', 'hour_cos', 'dow_sin', 'dow_cos', 'avg_speed', 'occupancy', 'avg_speed_lag1', 'avg_speed_lag2', 'avg_speed_lag3', 'occupancy_lag1', 'occupancy_lag2', 'occupancy_lag3', 'vehicle_count_lag1', 'vehicle_count_lag2', 'vehicle_count_lag3', 'vehicle_count_rmean_3', 'vehicle_count_rstd_3']\n",
      "Saved scaler to: model/scaler.joblib\n",
      "Scaled train set: 4209 rows\n",
      "Scaled val set: 903 rows\n",
      "Scaled test set: 900 rows\n",
      "X_train shape: (4173, 12, 17)\n",
      "y_train shape: (4173, 1)\n",
      "X_val shape: (867, 12, 17)\n",
      "X_test shape: (864, 12, 17)\n",
      "Reshaped targets to 1D arrays\n",
      "Saved numpy arrays to model/\n",
      "Timesteps, features: 12 17\n",
      "Keras example (commented):  \n",
      "from tensorflow.keras.models import Sequential\n",
      "from tensorflow.keras.layers import LSTM, Dense, Dropout\n",
      "from tensorflow.keras.optimizers import Adam\n",
      "\n",
      "model = Sequential([\n",
      "    LSTM(64, input_shape=(n_timesteps, n_features), return_sequences=False),\n",
      "    Dropout(0.2),\n",
      "    Dense(32, activation='relu'),\n",
      "    Dense(1)  # for horizon==1; for multi-step, Dense(horizon)\n",
      "])\n",
      "model.compile(optimizer=Adam(1e-3), loss='mse', metrics=['mae'])\n",
      "model.summary()\n",
      "# model.fit(X_train, y_train, validation_data=(X_val, y_val), epochs=50, batch_size=64)\n",
      "\n",
      "PyTorch is available — TimeSeriesDataset class created.\n",
      "Feature engineering complete. Ready for LSTM training.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Asus\\AppData\\Local\\Temp\\ipykernel_3024\\3290464597.py:234: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  d[present_features] = scaler.transform(d[present_features])\n",
      "C:\\Users\\Asus\\AppData\\Local\\Temp\\ipykernel_3024\\3290464597.py:234: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  d[present_features] = scaler.transform(d[present_features])\n",
      "C:\\Users\\Asus\\AppData\\Local\\Temp\\ipykernel_3024\\3290464597.py:234: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  d[present_features] = scaler.transform(d[present_features])\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# ---------------------------\n",
    "# LSTM-ready feature engineering (single-cell)\n",
    "# ---------------------------\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import joblib\n",
    "from datetime import timedelta\n",
    "\n",
    "# Optional: PyTorch dataset (only if you use PyTorch)\n",
    "try:\n",
    "    import torch\n",
    "    from torch.utils.data import Dataset\n",
    "    TORCH_AVAILABLE = True\n",
    "except Exception:\n",
    "    TORCH_AVAILABLE = False\n",
    "\n",
    "# ---------------------------\n",
    "# PARAMETERS (edit as needed)\n",
    "# ---------------------------\n",
    "DATA_PATH = \"C:/Users/Asus/Documents/Developers_Arena_Internship_Files/Month_6_Internship_files/traffic_flow_project/traffic_flow_project/data/synthetic_traffic_dataset.csv\"\n",
    "TIMESTAMP_COL = \"timestamp\"\n",
    "SENSOR_COL = \"sensor_id\"              # if multiple sensors present\n",
    "TARGET_COL = \"vehicle_count\"\n",
    "\n",
    "# windowing\n",
    "LOOKBACK = 12        # number of historical timesteps used as input (e.g., 12 * 5min = 60min if 5-min freq)\n",
    "HORIZON = 1          # how many steps ahead to predict (1 for next-step)\n",
    "STEP = 1             # stride while sliding window\n",
    "RESAMPLE_RULE = \"5T\" # resample to 5-minute intervals; change to \"1H\" etc. if your data differs\n",
    "\n",
    "SCALER_PATH = \"model/scaler.joblib\"\n",
    "\n",
    "# Ensure model dir exists\n",
    "os.makedirs(\"model\", exist_ok=True)\n",
    "\n",
    "# ---------------------------\n",
    "# 1) Load + basic preprocessing\n",
    "# ---------------------------\n",
    "print(\"Loading data from:\", DATA_PATH)\n",
    "df = pd.read_csv(DATA_PATH, parse_dates=[TIMESTAMP_COL])\n",
    "df = df.sort_values([SENSOR_COL, TIMESTAMP_COL]).reset_index(drop=True)\n",
    "print(\"Loaded:\", df.shape)\n",
    "display(df.head())\n",
    "\n",
    "# If timestamps are not regular, resample per sensor to a regular frequency (recommended for LSTM)\n",
    "def resample_sensor(sensor_df, rule=RESAMPLE_RULE, ts_col=TIMESTAMP_COL):\n",
    "    sensor_df = sensor_df.set_index(ts_col).sort_index()\n",
    "    # keep numerical columns and forward/backfill small gaps\n",
    "    numeric_cols = sensor_df.select_dtypes(include=\"number\").columns.tolist()\n",
    "    res = sensor_df[numeric_cols].resample(rule).mean()\n",
    "    # small gap filling: forward-fill then backward-fill (tune as needed)\n",
    "    res = res.ffill().bfill()\n",
    "    res = res.reset_index()\n",
    "    return res\n",
    "\n",
    "# Apply per sensor (if you have only one sensor, this is still fine)\n",
    "sensor_groups = []\n",
    "for s, g in df.groupby(SENSOR_COL):\n",
    "    g_res = resample_sensor(g, rule=RESAMPLE_RULE)\n",
    "    g_res[SENSOR_COL] = s\n",
    "    sensor_groups.append(g_res)\n",
    "df_reg = pd.concat(sensor_groups, ignore_index=True).sort_values([SENSOR_COL, TIMESTAMP_COL])\n",
    "print(\"After resampling:\", df_reg.shape)\n",
    "display(df_reg.head())\n",
    "\n",
    "# ---------------------------\n",
    "# 2) Time features (cyclical) + basic features\n",
    "# ---------------------------\n",
    "def add_time_features(df, ts_col=TIMESTAMP_COL):\n",
    "    df[\"hour\"] = df[ts_col].dt.hour\n",
    "    df[\"minute\"] = df[ts_col].dt.minute\n",
    "    df[\"dayofweek\"] = df[ts_col].dt.dayofweek  # Monday=0\n",
    "    # cyclical encoding\n",
    "    df[\"hour_sin\"] = np.sin(2 * np.pi * df[\"hour\"] / 24)\n",
    "    df[\"hour_cos\"] = np.cos(2 * np.pi * df[\"hour\"] / 24)\n",
    "    df[\"dow_sin\"] = np.sin(2 * np.pi * df[\"dayofweek\"] / 7)\n",
    "    df[\"dow_cos\"] = np.cos(2 * np.pi * df[\"dayofweek\"] / 7)\n",
    "    return df\n",
    "\n",
    "df_reg = add_time_features(df_reg)\n",
    "display(df_reg.head())\n",
    "\n",
    "# ---------------------------\n",
    "# 3) Lag & rolling features\n",
    "# ---------------------------\n",
    "def create_lag_features(df, numeric_cols, lags=[1,2,3,4,6,12]):\n",
    "    for lag in lags:\n",
    "        for col in numeric_cols:\n",
    "            df[f\"{col}_lag{lag}\"] = df.groupby(SENSOR_COL)[col].shift(lag)\n",
    "    return df\n",
    "\n",
    "def create_rolling_features(df, numeric_cols, windows=[3,6,12]):\n",
    "    for w in windows:\n",
    "        for col in numeric_cols:\n",
    "            df[f\"{col}_rmean_{w}\"] = df.groupby(SENSOR_COL)[col].shift(1).rolling(w).mean().reset_index(level=0, drop=True)\n",
    "            df[f\"{col}_rstd_{w}\"]  = df.groupby(SENSOR_COL)[col].shift(1).rolling(w).std().reset_index(level=0, drop=True)\n",
    "    return df\n",
    "\n",
    "numeric_cols = [\"avg_speed\", \"occupancy\", TARGET_COL]\n",
    "df_reg = create_lag_features(df_reg, numeric_cols=numeric_cols, lags=[1,2,3,6,12])\n",
    "df_reg = create_rolling_features(df_reg, numeric_cols=numeric_cols, windows=[3,6,12])\n",
    "\n",
    "# ---------------------------\n",
    "# 4) Drop rows with NaNs created by lagging\n",
    "# ---------------------------\n",
    "pre_drop = len(df_reg)\n",
    "df_reg = df_reg.dropna().reset_index(drop=True)\n",
    "post_drop = len(df_reg)\n",
    "print(f\"Dropped {pre_drop - post_drop} rows due to lag/rolling NaNs. Remaining: {post_drop}\")\n",
    "\n",
    "# ---------------------------\n",
    "# 5) Feature selection & scaling\n",
    "# ---------------------------\n",
    "# Choose features for model input\n",
    "feature_cols = [\n",
    "    # time cyclical\n",
    "    \"hour_sin\", \"hour_cos\", \"dow_sin\", \"dow_cos\",\n",
    "    # numeric base features\n",
    "    \"avg_speed\", \"occupancy\",\n",
    "    # lag features\n",
    "    \"avg_speed_lag1\",\"avg_speed_lag2\",\"avg_speed_lag3\",\n",
    "    \"occupancy_lag1\",\"occupancy_lag2\",\"occupancy_lag3\",\n",
    "    \"vehicle_count_lag1\",\"vehicle_count_lag2\",\"vehicle_count_lag3\",\n",
    "    # rolling\n",
    "    \"vehicle_count_rmean_3\", \"vehicle_count_rstd_3\"\n",
    "]\n",
    "\n",
    "# Ensure chosen columns exist (some may not if you changed lag windows)\n",
    "feature_cols = [c for c in feature_cols if c in df_reg.columns]\n",
    "print(\"Using feature cols:\", feature_cols)\n",
    "\n",
    "# Prepare target\n",
    "df_reg[\"target\"] = df_reg.groupby(SENSOR_COL)[TARGET_COL].shift(-HORIZON+1)  # for one-step ahead this is shift(0) but keeping pattern\n",
    "\n",
    "# Drop any remaining NaNs\n",
    "df_reg = df_reg.dropna(subset=feature_cols + [\"target\"]).reset_index(drop=True)\n",
    "print(\"After final drop:\", df_reg.shape)\n",
    "display(df_reg.head())\n",
    "\n",
    "# ---------------------------\n",
    "# 6) Train/Val/Test split (time-based)\n",
    "# ---------------------------\n",
    "def train_val_test_split_time(df, test_days=7, val_days=7, ts_col=TIMESTAMP_COL):\n",
    "    # Splits data by time (global) — good for time-series\n",
    "    last_ts = df[ts_col].max()\n",
    "    test_start = last_ts - pd.Timedelta(days=test_days)\n",
    "    val_start = test_start - pd.Timedelta(days=val_days)\n",
    "    train_df = df[df[ts_col] < val_start]\n",
    "    val_df = df[(df[ts_col] >= val_start) & (df[ts_col] < test_start)]\n",
    "    test_df = df[df[ts_col] >= test_start]\n",
    "    return train_df, val_df, test_df\n",
    "\n",
    "train_df, val_df, test_df = train_val_test_split_time(df_reg, test_days=7, val_days=7)\n",
    "print(\"Train/Val/Test shapes:\", train_df.shape, val_df.shape, test_df.shape)\n",
    "\n",
    "# Fit scaler on train features only\n",
    "\n",
    "# ---------------------------\n",
    "# Robust Train/Val/Test split + Scaler (fallbacks)\n",
    "# ---------------------------\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import joblib\n",
    "\n",
    "# Parameters (you can keep or change)\n",
    "TEST_DAYS = 7\n",
    "VAL_DAYS = 7\n",
    "SCALER_PATH = \"model/scaler.joblib\"\n",
    "\n",
    "# Diagnostics\n",
    "print(\"TOTAL rows:\", len(df_reg))\n",
    "print(\"Timestamp range:\", df_reg[TIMESTAMP_COL].min(), \"to\", df_reg[TIMESTAMP_COL].max())\n",
    "print(\"Unique sensors:\", df_reg[SENSOR_COL].nunique())\n",
    "print(\"Rows per sensor:\\n\", df_reg[SENSOR_COL].value_counts())\n",
    "\n",
    "# 1) Try deterministic day-based split (original)\n",
    "def split_by_days(df, test_days=TEST_DAYS, val_days=VAL_DAYS, ts_col=TIMESTAMP_COL):\n",
    "    last_ts = df[ts_col].max()\n",
    "    test_start = last_ts - pd.Timedelta(days=test_days)\n",
    "    val_start = test_start - pd.Timedelta(days=val_days)\n",
    "    train_df = df[df[ts_col] < val_start]\n",
    "    val_df = df[(df[ts_col] >= val_start) & (df[ts_col] < test_start)]\n",
    "    test_df = df[df[ts_col] >= test_start]\n",
    "    return train_df, val_df, test_df\n",
    "\n",
    "train_df, val_df, test_df = split_by_days(df_reg, TEST_DAYS, VAL_DAYS)\n",
    "print(\"After day-split -> Train/Val/Test sizes:\", len(train_df), len(val_df), len(test_df))\n",
    "\n",
    "# 2) If TRAIN is empty (or too small), try a quantile time split fallback\n",
    "if len(train_df) < 1:\n",
    "    print(\"Day-split produced empty/too-small train set. Falling back to time-quantile split.\")\n",
    "    t1 = df_reg[TIMESTAMP_COL].quantile(0.70)  # train until 70% time\n",
    "    t2 = df_reg[TIMESTAMP_COL].quantile(0.85)  # val until 85% time\n",
    "    train_df = df_reg[df_reg[TIMESTAMP_COL] <= t1]\n",
    "    val_df = df_reg[(df_reg[TIMESTAMP_COL] > t1) & (df_reg[TIMESTAMP_COL] <= t2)]\n",
    "    test_df = df_reg[df_reg[TIMESTAMP_COL] > t2]\n",
    "    print(\"After quantile-split -> Train/Val/Test sizes:\", len(train_df), len(val_df), len(test_df))\n",
    "\n",
    "# 3) If still small/empty, fallback to proportional index split (70/15/15)\n",
    "if len(train_df) < 1 or len(val_df) < 1 or len(test_df) < 1:\n",
    "    print(\"Quantile-split insufficient. Using proportional index-based split (70/15/15).\")\n",
    "    df_sorted = df_reg.sort_values(TIMESTAMP_COL).reset_index(drop=True)\n",
    "    n = len(df_sorted)\n",
    "    if n < 3:\n",
    "        raise ValueError(\"Dataset too small for splitting. Need at least 3 rows.\")\n",
    "    i1 = int(n * 0.70)\n",
    "    i2 = int(n * 0.85)\n",
    "    train_df = df_sorted.iloc[:i1].copy()\n",
    "    val_df = df_sorted.iloc[i1:i2].copy()\n",
    "    test_df = df_sorted.iloc[i2:].copy()\n",
    "    print(\"After proportional-split -> Train/Val/Test sizes:\", len(train_df), len(val_df), len(test_df))\n",
    "\n",
    "# Final safety check: ensure feature columns exist and we have samples\n",
    "if len(train_df) == 0:\n",
    "    raise ValueError(\"Training set is empty after all fallback splits. Check your timestamps and data size.\")\n",
    "\n",
    "# Make sure feature columns exist in data\n",
    "present_features = [c for c in feature_cols if c in train_df.columns]\n",
    "if len(present_features) == 0:\n",
    "    raise ValueError(f\"No feature columns present for scaling. Available cols in train: {train_df.columns.tolist()}\")\n",
    "\n",
    "print(\"Using feature columns for scaler:\", present_features)\n",
    "\n",
    "# Fit scaler on train features only\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(train_df[present_features])\n",
    "joblib.dump(scaler, SCALER_PATH)\n",
    "print(\"Saved scaler to:\", SCALER_PATH)\n",
    "\n",
    "# Apply scaler to train/val/test for present features\n",
    "for dname, d in [(\"train\", train_df), (\"val\", val_df), (\"test\", test_df)]:\n",
    "    if len(d) > 0:\n",
    "        d[present_features] = scaler.transform(d[present_features])\n",
    "        print(f\"Scaled {dname} set: {len(d)} rows\")\n",
    "    else:\n",
    "        print(f\"{dname} set empty; skipping scaling.\")\n",
    "\n",
    "# ---------------------------\n",
    "# 7) Sequence creation (sliding window)\n",
    "# ---------------------------\n",
    "def create_sequences_from_df(df, feature_columns, lookback=LOOKBACK, horizon=HORIZON, step=STEP):\n",
    "    \"\"\"\n",
    "    Returns X: (n_samples, lookback, n_features), y: (n_samples, horizon)\n",
    "    This function assumes df is sorted by [sensor, timestamp].\n",
    "    We slide within each sensor independently to avoid mixing sensors in a window.\n",
    "    \"\"\"\n",
    "    Xs, ys = [], []\n",
    "    sensors = df[SENSOR_COL].unique()\n",
    "    for s in sensors:\n",
    "        s_df = df[df[SENSOR_COL]==s].sort_values(TIMESTAMP_COL)\n",
    "        feature_vals = s_df[feature_columns].values\n",
    "        target_vals = s_df[\"target\"].values\n",
    "        n = len(s_df)\n",
    "        # sliding window\n",
    "        for start in range(0, n - lookback - horizon + 1, step):\n",
    "            end = start + lookback\n",
    "            X = feature_vals[start:end]\n",
    "            y = target_vals[end:end+horizon]  # shape (horizon,)\n",
    "            Xs.append(X)\n",
    "            ys.append(y)\n",
    "    Xs = np.array(Xs)\n",
    "    ys = np.array(ys)\n",
    "    return Xs, ys\n",
    "\n",
    "X_train, y_train = create_sequences_from_df(train_df, feature_cols, lookback=LOOKBACK, horizon=HORIZON, step=STEP)\n",
    "X_val, y_val     = create_sequences_from_df(val_df, feature_cols, lookback=LOOKBACK, horizon=HORIZON, step=STEP)\n",
    "X_test, y_test   = create_sequences_from_df(test_df, feature_cols, lookback=LOOKBACK, horizon=HORIZON, step=STEP)\n",
    "\n",
    "print(\"X_train shape:\", X_train.shape)\n",
    "print(\"y_train shape:\", y_train.shape)\n",
    "print(\"X_val shape:\", X_val.shape)\n",
    "print(\"X_test shape:\", X_test.shape)\n",
    "\n",
    "# If horizon==1, reshape y to (n_samples,) for convenience\n",
    "if y_train.ndim == 2 and y_train.shape[1] == 1:\n",
    "    y_train = y_train.ravel()\n",
    "    y_val = y_val.ravel()\n",
    "    y_test = y_test.ravel()\n",
    "    print(\"Reshaped targets to 1D arrays\")\n",
    "\n",
    "# Save arrays for training reuse\n",
    "np.save(\"model/X_train.npy\", X_train)\n",
    "np.save(\"model/y_train.npy\", y_train)\n",
    "np.save(\"model/X_val.npy\", X_val)\n",
    "np.save(\"model/y_val.npy\", y_val)\n",
    "np.save(\"model/X_test.npy\", X_test)\n",
    "np.save(\"model/y_test.npy\", y_test)\n",
    "print(\"Saved numpy arrays to model/\")\n",
    "\n",
    "# ---------------------------\n",
    "# 8) Example Keras-ready shapes and quick model (TensorFlow/Keras)\n",
    "# ---------------------------\n",
    "n_timesteps = X_train.shape[1] if X_train.size else LOOKBACK\n",
    "n_features  = X_train.shape[2] if X_train.size else len(feature_cols)\n",
    "print(\"Timesteps, features:\", n_timesteps, n_features)\n",
    "\n",
    "keras_example = \"\"\" \n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense, Dropout\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "model = Sequential([\n",
    "    LSTM(64, input_shape=(n_timesteps, n_features), return_sequences=False),\n",
    "    Dropout(0.2),\n",
    "    Dense(32, activation='relu'),\n",
    "    Dense(1)  # for horizon==1; for multi-step, Dense(horizon)\n",
    "])\n",
    "model.compile(optimizer=Adam(1e-3), loss='mse', metrics=['mae'])\n",
    "model.summary()\n",
    "# model.fit(X_train, y_train, validation_data=(X_val, y_val), epochs=50, batch_size=64)\n",
    "\"\"\"\n",
    "print(\"Keras example (commented):\", keras_example)\n",
    "\n",
    "# ---------------------------\n",
    "# 9) Optional: PyTorch Dataset wrapper\n",
    "# ---------------------------\n",
    "if TORCH_AVAILABLE:\n",
    "    class TimeSeriesDataset(Dataset):\n",
    "        def __init__(self, X, y, device=None):\n",
    "            self.X = torch.tensor(X, dtype=torch.float32)\n",
    "            self.y = torch.tensor(y, dtype=torch.float32)\n",
    "            self.device = device\n",
    "        def __len__(self):\n",
    "            return len(self.X)\n",
    "        def __getitem__(self, idx):\n",
    "            return self.X[idx], self.y[idx]\n",
    "    # Example usage:\n",
    "    # train_ds = TimeSeriesDataset(X_train, y_train)\n",
    "    # from torch.utils.data import DataLoader\n",
    "    # train_loader = DataLoader(train_ds, batch_size=64, shuffle=True)\n",
    "    print(\"PyTorch is available — TimeSeriesDataset class created.\")\n",
    "else:\n",
    "    print(\"PyTorch not available in this environment; skip PyTorch dataset creation.\")\n",
    "\n",
    "# ---------------------------\n",
    "# DONE\n",
    "# ---------------------------\n",
    "print(\"Feature engineering complete. Ready for LSTM training.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2a4c3df",
   "metadata": {},
   "source": [
    "# Modeling\n",
    "\n",
    "Feature engineering and training example (RandomForest + LSTM outline)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "df242070",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE: 0.0022975206611570305\n",
      "Saved model to model/joblib_model.joblib\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "\n",
    "\n",
    "df = pd.read_csv(DATA_PATH, parse_dates=['timestamp'])\n",
    "df['hour'] = df['timestamp'].dt.hour\n",
    "X = df[['sensor_id','hour','avg_speed','occupancy']].fillna(0)\n",
    "y = df['vehicle_count']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y,test_size=0.2,random_state=42)\n",
    "model = RandomForestRegressor(n_estimators=50, random_state=42)\n",
    "model.fit(X_train, y_train)\n",
    "pred = model.predict(X_test)\n",
    "print('MAE:', mean_absolute_error(y_test, pred))\n",
    "# Save model\n",
    "import joblib\n",
    "import os\n",
    "os.makedirs('model', exist_ok=True)\n",
    "joblib.dump(model, 'model/joblib_model.joblib')\n",
    "print('Saved model to model/joblib_model.joblib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca840956",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
